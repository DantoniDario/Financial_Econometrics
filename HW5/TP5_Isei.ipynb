{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats \n",
    "import statistics \n",
    "\n",
    "#excersise 1 \n",
    "\n",
    "#1.1 \n",
    "#Simulate 3 samples of 1000 observations from the normal distribution,\n",
    "#keepingthe mean constant but with different standard deviations \n",
    "#(half the mean, sameas the mean, twice the mean).\n",
    "\n",
    "mu=10\n",
    "std1=mu/2\n",
    "std2=mu\n",
    "std3=mu*2\n",
    "simulate1= np.random.normal(mu, std1, 1000)\n",
    "simulate2= np.random.normal(mu, std2, 1000)\n",
    "simulate3= np.random.normal(mu, std3, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2\n",
    "\n",
    "def mu_mle(x):\n",
    "#x the simulate observation\n",
    "   return [(1/len(x))*sum((x))]\n",
    "\n",
    "def var_mle(x,y):\n",
    "#x the simulated observation\n",
    "#y is the estimated mle mean \n",
    "    return([(1/len(x))*sum((x-y)**2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 \n",
    "\n",
    "mu_mle1=mu_mle(simulate1)\n",
    "mu_mle2=mu_mle(simulate2)\n",
    "mu_mle3=mu_mle(simulate3)\n",
    "\n",
    "var_mle1=var_mle(simulate1, mu_mle1)\n",
    "var_mle2=var_mle(simulate2, mu_mle2)\n",
    "var_mle3=var_mle(simulate3, mu_mle3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.669296897976134, 405.643562393779]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.5 \n",
    "#Python sheet to estimate the\n",
    "#parameters of a normallaw by maximum likelihood\n",
    "\n",
    "#we can use the function statistics as it finds the moments byusing the maximum likelihood \n",
    "\n",
    "def moments(x):\n",
    "    from scipy import stats \n",
    "    import statistics\n",
    "    return([statistics.mean(x), statistics.variance(x)])\n",
    "\n",
    "#1.5\n",
    "moments(simulate1)\n",
    "moments(simulate2)\n",
    "moments(simulate3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Observations - Y1</td>\n",
       "      <td>Observations - Y2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.19687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.0469155</td>\n",
       "      <td>-0.479625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0125147</td>\n",
       "      <td>-0.146074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0595525</td>\n",
       "      <td>0.564166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0.102728</td>\n",
       "      <td>1.01681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.0648015</td>\n",
       "      <td>0.627088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0.0397571</td>\n",
       "      <td>0.366213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.0351448</td>\n",
       "      <td>0.309696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>0.0686657</td>\n",
       "      <td>0.634562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     X                  Y\n",
       "0    Observations - Y1  Observations - Y2\n",
       "1             0.019687            0.19687\n",
       "2           -0.0469155          -0.479625\n",
       "3           -0.0125147          -0.146074\n",
       "4            0.0595525           0.564166\n",
       "..                 ...                ...\n",
       "362           0.102728            1.01681\n",
       "363          0.0648015           0.627088\n",
       "364          0.0397571           0.366213\n",
       "365          0.0351448           0.309696\n",
       "366          0.0686657           0.634562\n",
       "\n",
       "[367 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "#Data = pd.read_excel(\"/files/exercises/Homeworks/HW5/TP5.xls\", skiprows = 4)\n",
    "#Data.columns = ['bosh','A','X','B','Y']\n",
    "#newData=df.Dataframe(Data)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"/files/exercises/Homeworks/HW5/TP5.xls\")\n",
    "df.columns = ['bosh','A','X','B','Y']\n",
    "df.drop(['bosh', 'A', 'B'], axis=1) #axis=1 dmth qe hiq kolone\n",
    "\n",
    "#can find a way to remove the first row \n",
    "#df.drop(df.index[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivariatekernel(data1, data2, nb_points, bandwidth = None):\n",
    "    \"\"\"\n",
    "    points = bivariatekernel(data1,data2,nbpoints,bandwidth)\n",
    "    \n",
    "    The function bivariatekernel estimates the density of the distribution underlying the sample with the non-parametric gaussian kernel method. \n",
    "    \n",
    "    Remark:\n",
    "    - The density is estimated between the min and the max of the sample of observations, for nb_points equidistant points.\n",
    "    - If the bandwidth parameter is omitted, the \"rule of thumb\" is applied.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data1 : array\n",
    "        the vector of observations of the sample 1 \n",
    "    data2 : array\n",
    "        the vector of observations of the sample 2 with the same length of sample 1\n",
    "    nb_points : int\n",
    "        the number of points where the density is estimated (see the remark) \n",
    "    bandwidth : double\n",
    "        the length of the window (optional argument)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    points\n",
    "        a matrix (3,nb_points^2) where first two rows contain the estimation points and the 3rd contains the values of the density.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if not (isinstance(data1, np.ndarray) & isinstance(data2, np.ndarray)):\n",
    "        print('Error: please transfer the input variables to arrays first!')\n",
    "\n",
    "    if data1.ndim != 1 | data2.ndim != 1:\n",
    "        print('Error: please transfer the input variable to an one-dimension array!')\n",
    "\n",
    "    if data1.shape[0] != data2.shape[0]:\n",
    "        print('Error: please align two arrays with the same length!')\n",
    "\n",
    "    nbdata = len(data1)\n",
    "\n",
    "\n",
    "    # The bandwidth argument of the function gaussiankernel is optional. If no value is passed for the bandwith, the program use the \"rule of thumb\"\n",
    "    if bandwidth is None:\n",
    "        bandwidth = mean([pow(nbdata, -0.2) * pow(variance(data1), 0.5), pow(nbdata, -0.2) * pow(variance(data2), 0.5)])\n",
    "\n",
    "\n",
    "    # Creation of the grid of points\n",
    "    pts_1 = np.linspace(min(data1), max(data1), nb_points)\n",
    "    pts_2 = np.linspace(min(data2), max(data2), nb_points)\n",
    "\n",
    "    points_1 = np.concatenate(np.outer(pts_1, np.ones(nb_points)), axis=None)\n",
    "    points_2 = np.concatenate(np.outer(np.ones(nb_points), pts_2), axis=None)\n",
    "\n",
    "    # We calculate all the points in one step by using the functions mean and the kronecker product.\n",
    "    # This is the most compact and efficient writing as it optimizes the use of the preprogrammed functions. You should \"vectorize\" the code at best to obtain a good performance.\n",
    "    # Check the help on different functions for more details.\n",
    "\n",
    "    y1 = (np.outer(data1, np.ones(int(pow(nb_points,2)))) - np.outer(np.ones(nbdata), points_1))/bandwidth\n",
    "    y2 = (np.outer(data2, np.ones(int(pow(nb_points,2)))) - np.outer(np.ones(nbdata), points_2))/bandwidth\n",
    "    k1 = np.exp(-0.5*np.power(y1, 2))/np.power(2*pi,0.5)\n",
    "    k2 = np.exp(-0.5*np.power(y2, 2))/np.power(2*pi,0.5)\n",
    "    f = np.mean(k1*k2, axis = 0)/pow(bandwidth,2)\n",
    "\n",
    "    points = [points_1, points_2, f]\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condmean_kernel(data1, data2, nb_points, bandwidth = None)\n",
    "\n",
    "#The function condmean_kernel estimates the conditional mean of y given x\n",
    "#with the non-parametric method of the gaussian kernel.\n",
    "\n",
    "#we count the length of the sample \n",
    "nbdata = len(data1)\n",
    "\n",
    "#The last input argument of the function gaussiankernel is optional. If no\n",
    "# value is passed for bandwith, the program uses the so called \"rule of\n",
    "# thumb\"\n",
    "\n",
    "if bandwidth is None:\n",
    "        bandwidth = mean([pow(nbdata, -0.2) * pow(variance(data1), 0.5), pow(nbdata, -0.2) * pow(variance(data2), 0.5)])\n",
    "        \n",
    "#if nargin==3 \n",
    "#    % no, then we apply the \"rule of thumb\"\n",
    "#    bandwidth=(nbdata^(-0.2))*(var(x)^0.5);\n",
    "#end\n",
    "\n",
    "#creation of the grid of points\n",
    "\n",
    "#MaxObs=max(x);\n",
    "#MinObs=min(x);\n",
    "#step=(MaxObs-MinObs)/(nb_points-1);\n",
    "#points=[MinObs:step:MaxObs];\n",
    "\n",
    " # Creation of the grid of points\n",
    "    pts_1 = np.linspace(min(data1), max(data1), nb_points)\n",
    "    pts_2 = np.linspace(min(data2), max(data2), nb_points)\n",
    "\n",
    "    points_1 = np.concatenate(np.outer(pts_1, np.ones(nb_points)), axis=None)\n",
    "    points_2 = np.concatenate(np.outer(np.ones(nb_points), pts_2), axis=None)\n",
    "\n",
    "\n",
    "    y1 = (np.outer(data1, np.ones(int(pow(nb_points,2)))) - np.outer(np.ones(nbdata), points_1))/bandwidth\n",
    "    y2 = (np.outer(data2, np.ones(int(pow(nb_points,2)))) - np.outer(np.ones(nbdata), points_2))/bandwidth\n",
    "    k1 = np.exp(-0.5*np.power(y1, 2))/np.power(2*pi,0.5)\n",
    "    k2 = np.exp(-0.5*np.power(y2, 2))/np.power(2*pi,0.5)\n",
    "    f = np.mean(k1*k2, axis = 0)/pow(bandwidth,2)\n",
    "\n",
    "    points = [points_1, points_2, f]\n",
    "    \n",
    "    \n",
    "#calculation of the joint density y times \n",
    "tmp=mean(np.exp(np.power(-0.5*((np.kron(x,ones(1,nb_points))-np.kron(ones(nbdata,1),points))/bandwidth),0.5)*np.kron(y,ones(1,nb_points)),1)/bandwidth/np.power(2*pi,2);\n",
    "\n",
    "#calculation of the marginal density \n",
    "tmp2=mean(np.exp(-0.5*(np.power(((np.kron(x,ones(1,nb_points),0.5)-np.kron(ones(nbdata,1),points))/bandwidth)),1)/bandwidth/np.power(2*pi,2);\n",
    "\n",
    "condmean=[points;tmp/tmp2]; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-9890b83a9b8d>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-9890b83a9b8d>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    bandwidth = (np.power(N;-0.2))*pow(variance(data1), 0.5)/2\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#usign the kernel estimation function \n",
    "N=len(X)\n",
    "\n",
    "bandwidth = (np.power(N;-0.2))*pow(variance(data1), 0.5)/2\n",
    "condmean = condmean_kernel(y,x,200,bandwidth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "datahub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
