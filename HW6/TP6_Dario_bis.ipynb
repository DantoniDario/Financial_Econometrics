{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import statistics\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import norm\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"/files/exercises/Homeworks/HW6/TP6.xls\", skiprows = 4)\n",
    "data = data.drop([0])\n",
    "data = data.drop('Name', axis = 1)\n",
    "data = data.astype(float)\n",
    "names_company = data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 5% : -0.09334706228021589 \n",
      "Quantile 1% : -0.14053384957574752\n"
     ]
    }
   ],
   "source": [
    "quant_5 = np.quantile(data.iloc[:,0], 0.05)\n",
    "quant_1 = np.quantile(data.iloc[:,0], 0.01)\n",
    "print('Quantile 5% :', quant_5, '\\nQuantile 1% :', quant_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VaR estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.repeat(0.1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pd.DataFrame(np.dot(data,weights.T), columns = ['Portfolio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.ones(10)\n",
    "for i in range(0,10):\n",
    "    means[i] = stats.norm.fit(data.iloc[:,i].values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estim. mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMER.EXPRESS</th>\n",
       "      <td>0.002125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AOL TIME WARNER</th>\n",
       "      <td>0.006818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT &amp; T</th>\n",
       "      <td>-0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK &amp; DECKER</th>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLGATE - PALM.</th>\n",
       "      <td>0.001985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FORD MOTOR</th>\n",
       "      <td>-0.002714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCDONALDS</th>\n",
       "      <td>-0.000633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PFIZER</th>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEXAS INSTS.</th>\n",
       "      <td>0.003713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAL MART STORES</th>\n",
       "      <td>0.004473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Estim. mean\n",
       "AMER.EXPRESS        0.002125\n",
       "AOL TIME WARNER     0.006818\n",
       "AT & T             -0.001802\n",
       "BLACK & DECKER      0.001037\n",
       "COLGATE - PALM.     0.001985\n",
       "FORD MOTOR         -0.002714\n",
       "MCDONALDS          -0.000633\n",
       "PFIZER              0.001445\n",
       "TEXAS INSTS.        0.003713\n",
       "WAL MART STORES     0.004473"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(means, index = names_company, columns = ['Estim. mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMER.EXPRESS</th>\n",
       "      <th>AOL TIME WARNER</th>\n",
       "      <th>AT &amp; T</th>\n",
       "      <th>BLACK &amp; DECKER</th>\n",
       "      <th>COLGATE - PALM.</th>\n",
       "      <th>FORD MOTOR</th>\n",
       "      <th>MCDONALDS</th>\n",
       "      <th>PFIZER</th>\n",
       "      <th>TEXAS INSTS.</th>\n",
       "      <th>WAL MART STORES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AMER.EXPRESS</th>\n",
       "      <td>0.003577</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.001452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AOL TIME WARNER</th>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.008194</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.001538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT &amp; T</th>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.000930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK &amp; DECKER</th>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLGATE - PALM.</th>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>0.000795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FORD MOTOR</th>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCDONALDS</th>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PFIZER</th>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEXAS INSTS.</th>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.000842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAL MART STORES</th>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.002521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AMER.EXPRESS  AOL TIME WARNER    AT & T  BLACK & DECKER  \\\n",
       "AMER.EXPRESS         0.003577         0.002002  0.001275        0.001368   \n",
       "AOL TIME WARNER      0.002002         0.008194  0.002115        0.000926   \n",
       "AT & T               0.001275         0.002115  0.003846        0.000431   \n",
       "BLACK & DECKER       0.001368         0.000926  0.000431        0.003101   \n",
       "COLGATE - PALM.      0.000972         0.000208 -0.000034        0.000768   \n",
       "FORD MOTOR           0.001493         0.001560  0.000832        0.001107   \n",
       "MCDONALDS            0.000864         0.001164  0.000449        0.000757   \n",
       "PFIZER               0.000968         0.001167  0.000317        0.000343   \n",
       "TEXAS INSTS.         0.001806         0.002718  0.001796        0.000951   \n",
       "WAL MART STORES      0.001452         0.001538  0.000930        0.001151   \n",
       "\n",
       "                 COLGATE - PALM.  FORD MOTOR  MCDONALDS    PFIZER  \\\n",
       "AMER.EXPRESS            0.000972    0.001493   0.000864  0.000968   \n",
       "AOL TIME WARNER         0.000208    0.001560   0.001164  0.001167   \n",
       "AT & T                 -0.000034    0.000832   0.000449  0.000317   \n",
       "BLACK & DECKER          0.000768    0.001107   0.000757  0.000343   \n",
       "COLGATE - PALM.         0.002235    0.000434   0.000517  0.000827   \n",
       "FORD MOTOR              0.000434    0.002637   0.000662  0.000491   \n",
       "MCDONALDS               0.000517    0.000662   0.002075  0.000531   \n",
       "PFIZER                  0.000827    0.000491   0.000531  0.002227   \n",
       "TEXAS INSTS.           -0.000140    0.001297   0.000690  0.000341   \n",
       "WAL MART STORES         0.000795    0.000983   0.000546  0.000761   \n",
       "\n",
       "                 TEXAS INSTS.  WAL MART STORES  \n",
       "AMER.EXPRESS         0.001806         0.001452  \n",
       "AOL TIME WARNER      0.002718         0.001538  \n",
       "AT & T               0.001796         0.000930  \n",
       "BLACK & DECKER       0.000951         0.001151  \n",
       "COLGATE - PALM.     -0.000140         0.000795  \n",
       "FORD MOTOR           0.001297         0.000983  \n",
       "MCDONALDS            0.000690         0.000546  \n",
       "PFIZER               0.000341         0.000761  \n",
       "TEXAS INSTS.         0.006745         0.000842  \n",
       "WAL MART STORES      0.000842         0.002521  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AR1 = data.iloc[:,0].values\n",
    "AR2 = data.iloc[:,1].values\n",
    "AR3 = data.iloc[:,2].values\n",
    "AR4 = data.iloc[:,3].values\n",
    "AR5 = data.iloc[:,4].values\n",
    "AR6 = data.iloc[:,5].values\n",
    "AR7 = data.iloc[:,6].values\n",
    "AR8 = data.iloc[:,7].values\n",
    "AR9 = data.iloc[:,8].values\n",
    "AR10 = data.iloc[:,9].values\n",
    "\n",
    "cov_asset = np.cov(np.array([AR1, AR2, AR3, AR4, AR5, AR6, AR7, AR8, AR9, AR10]))\n",
    "pd.DataFrame(cov_asset, index = names_company, columns = names_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness:  0.06314676534352914 \n",
      "Kurtosis:  1.1646283780273032\n"
     ]
    }
   ],
   "source": [
    "print('Skewness: ', stats.skew(pf.values)[0], '\\nKurtosis: ', stats.kurtosis(pf.values)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05606581682634763"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- np.dot(weights, means.T) - math.sqrt(np.dot(np.dot(weights, cov_asset.T), weights.T))*stats.norm.ppf(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianVaR(VaR, obs, bandwidth, alpha):\n",
    "    return (np.mean(stats.norm.cdf((-VaR - obs)/bandwidth))-alpha)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = np.reshape(pf.values, 243)\n",
    "bandwidth = pow(len(pf), -0.2) * pow(statistics.variance(np.reshape(pf.values, 243)), 0.5)\n",
    "alpha = 0.05\n",
    "guesses = -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 17\n",
      "         Function evaluations: 34\n"
     ]
    }
   ],
   "source": [
    "estimates_Var = optimize.fmin(func = gaussianVaR, x0 = guesses, args = (obs, bandwidth, alpha,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0580468749999995"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimates_Var[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivities of VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07183328, 0.09440863, 0.05786043, 0.05008028, 0.02887156,\n",
       "       0.05660511, 0.03933869, 0.03592766, 0.07620257, 0.04952996])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- means - np.dot(cov_asset, weights.T) / math.sqrt(np.dot(np.dot(weights, cov_asset.T), weights.T)) * stats.norm.ppf(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussiankernel(obs_x, obs_y, VaR_hat, bandwidth = None):\n",
    "    \"\"\"\n",
    "    kernel_pdf = gaussiankernel(obs,nb_column,bandwidth)\n",
    "    \n",
    "    The function gaussiankernel estimates the density of the distribution underlying the sample with the non-parametric gaussian kernel method.  \n",
    "    \n",
    "    Remark:\n",
    "    - The density is estimated between the min and the max of the sample of observations, for nb_points equidistant points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obs : array\n",
    "        a vector of observations \n",
    "    nb_column : int\n",
    "        the number of points where the density is estimated (see the remark) \n",
    "    bandwidth : double\n",
    "        the length of the window (optional argument)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    kernel_pdf\n",
    "        a matrix (2, nb_points) where the first row contains the estimation points and the second row contains the values of the density. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # the following calculations require obs to be an one-column array.\n",
    "    if not isinstance(obs_x, np.ndarray):\n",
    "        print('Error: please transfer the input variable to an array first!')\n",
    "    if not isinstance(obs_y, np.ndarray):\n",
    "        print('Error: please transfer the input variable to an array first!')\n",
    "    #if obs_x.ndim != 1:\n",
    "    #    print('Error: please transfer the input variable to an one-dimensional array!')\n",
    "\n",
    "    nb_obs = len(obs_x)\n",
    "    nb_column = obs_y.shape[1]\n",
    "    \n",
    "    # The 3rd input argument of the function gaussiankernel is optional.\n",
    "    # If no value is passed for the bandwith, the program will a \"rule of thumb\" value: (https://en.wikipedia.org/wiki/Kernel_density_estimation)\n",
    "    if bandwidth is None:\n",
    "        bandwidth = pow(nb_obs, -0.2) * pow(statistics.variance(obs_x.reshape(243)), 0.5)\n",
    "        \n",
    "\n",
    "    # We calculate all the points in one step by using the functions mean and the kronecker product.\n",
    "    # This is the most compact and efficient writing as it optimizes the use of the preprogrammed functions. You should \"vectorize\" the code at best to obtain a good performance.\n",
    "    # Check the help on different functions for more details.\n",
    "\n",
    "    x = (np.outer(obs_x, np.ones(nb_column)) + VaR_hat)/bandwidth\n",
    "    k = np.exp(-0.5*np.power(x, 2))/np.power(2*math.pi,0.5)\n",
    "    y = obs_y\n",
    "    f_above = np.mean((-y*k), axis = 0)/bandwidth\n",
    "    f_below = np.mean(k, axis=0)/bandwidth\n",
    "    f = f_above/f_below\n",
    "    kernel_pdf = f\n",
    "    \n",
    "    # Slow way: \n",
    "#     def calc_kernel(obs, x, bandwidth):\n",
    "#        return mean(np.exp((-0.5)*np.power((obs - x)/bandwidth, 2)))/bandwidth/np.power(2*pi,0.5)\n",
    "#     f = np.array([calc_kernel(obs, x, bandwidth) for x in kernel_pdf])\n",
    "\n",
    "    return kernel_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_x = pf.values\n",
    "obs_y = data.values\n",
    "VaR_hat = estimates_Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06637222, 0.08788811, 0.05978446, 0.04286349, 0.02365767,\n",
       "       0.04832397, 0.03919093, 0.0383557 , 0.0557471 , 0.04867303])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussiankernel(obs_x, obs_y, VaR_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with mean-variance optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_var(weight, cov_asset, obj, means):\n",
    "    return np.dot(np.dot(weight, cov_asset.T), weight.T)\n",
    "\n",
    "#def min_VaR(weight, cov_asset, obj, means):\n",
    "#    return (np.mean(stats.norm.cdf((-VaR - obs)/bandwidth))-alpha)**2\n",
    "\n",
    "def constr(weight):\n",
    "    return sum(weight) - 1\n",
    "\n",
    "def constr1(weight):\n",
    "    return np.dot(weight, means.T) - obj  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = np.repeat(0.1,10)\n",
    "obj = 0.05\n",
    "bnds = ((0,1),)*10\n",
    "cons = [{'type':'eq', 'fun': constr},\n",
    "        {'type':'eq', 'fun': constr1}]\n",
    "\n",
    "opt_weight = optimize.minimize(min_var, x0 = guesses, method = 'SLSQP', constraints=cons, args = (cov_asset, means, obj,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50372701,  1.66772605, -2.01405417,  0.06323794,  1.26027876,\n",
       "       -3.81231889, -1.33433282, -0.06352053,  1.16797902,  3.56127762])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_weight.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_VaR(VaR, data, weights, bandwidth, means):\n",
    "    obs = np.dot(data,weights.T)\n",
    "    return (np.mean(stats.norm.cdf((-VaR - obs)/bandwidth))-0.05)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,) (243,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-23c82d2baafb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         {'type':'eq', 'fun': constr1}]\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mopt_weight2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_VaR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguesses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SLSQP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/dhlib/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cobyla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'slsqp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         return _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    626\u001b[0m                                constraints, callback=callback, **options)\n\u001b[1;32m    627\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'trust-constr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dhlib/lib/python3.8/site-packages/scipy/optimize/slsqp.py\u001b[0m in \u001b[0;36m_minimize_slsqp\u001b[0;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;31m# ScalarFunction provides function and gradient evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     sf = _prepare_scalar_function(func, x, jac=jac, args=args, epsilon=eps,\n\u001b[0m\u001b[1;32m    369\u001b[0m                                   \u001b[0mfinite_diff_rel_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinite_diff_rel_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                                   bounds=new_bounds)\n",
      "\u001b[0;32m/dhlib/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[1;32m    262\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dhlib/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Gradient evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dhlib/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dhlib/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dhlib/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-a035bbc26f77>\u001b[0m in \u001b[0;36mmin_VaR\u001b[0;34m(VaR, data, weights, bandwidth, means)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmin_VaR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVaR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mVaR\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbandwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,) (243,) "
     ]
    }
   ],
   "source": [
    "data = data\n",
    "bandwidth = pow(len(data), -0.2) * pow(statistics.variance(obs_x.reshape(243)), 0.5)\n",
    "guesses = np.repeat(0.1,10)\n",
    "obj = 0.05\n",
    "bnds = ((0,1),)*10\n",
    "cons = [{'type':'eq', 'fun': constr},\n",
    "        {'type':'eq', 'fun': constr1}]\n",
    "\n",
    "opt_weight2 = optimize.minimize(min_VaR, x0 = guesses, method = 'SLSQP', constraints = cons, bounds = bnds, args = (data, means, obj, bandwidth,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "datahub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
